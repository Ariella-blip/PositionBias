{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f33176d-4966-4f40-a7ce-3c82e456ce6d",
   "metadata": {},
   "source": [
    "# Dense and Sparse Simulations Position Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ceeb860a-e969-4955-91ae-4437f8c4b57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faker --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23cf69fd-5c85-455b-a126-cfa823f3c055",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faker\n",
    "from sklearn.datasets import make_regression\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f27f5fe4-6dc1-4e7f-a347-5fc49cd73e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "faker.Faker.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5035c186-7d13-4c09-9a5c-306c085cad1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake = faker.Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c65bc06e-eea7-48c4-8e60-e68b99187236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# True bias\n",
    "true_bias = np.array([0.7, 0.6, 0.5, 0.4, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dabc4dfb-ca8b-412b-a584-acd244d2523b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_jobs(njobs):\n",
    "    \"\"\" \n",
    "    Generate random job ids beginning with J for clarity\n",
    "    \"\"\"\n",
    "    jobs = []\n",
    "    for idx in range(njobs):\n",
    "        jobs.append(str(fake.uuid4()))\n",
    "        jobs[-1] = \"J\" + jobs[-1][1:]\n",
    "    \n",
    "    return np.array(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f907aa80-4adc-4d52-af89-0f8d083ec26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_queries(nqueries):\n",
    "    \"\"\" \n",
    "    Generate random query ids beginning with Q for clarity\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    for idx in range(nqueries):\n",
    "        queries.append(str(fake.uuid4()))\n",
    "        queries[-1] = \"Q\" + queries[-1][1:]\n",
    "    \n",
    "    return np.array(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5c1014f-2c23-42a9-bc48-15aae1ac82d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_relevance(uniform = True, nfeats = 0, njobs = 105, nqueries = 50):\n",
    "    \"\"\"\n",
    "    Simulate relevance that is uniformly distributed or non-uniformly distributed\n",
    "    Additionally generates features if relevance is non-unifomrly distributed\n",
    "    \"\"\"\n",
    "\n",
    "    if uniform:\n",
    "        return np.random.random((njobs, nqueries))\n",
    "\n",
    "    # Simulate non-uniformly distributed relevance and features\n",
    "    nfeats = 20\n",
    "    features, relevance = make_regression(n_samples= nqueries * njobs, n_features = nfeats, n_informative = nfeats, noise= 100, random_state=99)\n",
    "        \n",
    "    # Recode relevance so that it is between 0 and 1\n",
    "    relevance = relevance - np.min(relevance)\n",
    "    relevance /= (np.max(relevance) - np.min(relevance))\n",
    "        \n",
    "    # Formatting\n",
    "    features = features.reshape(njobs, nqueries, nfeats)\n",
    "    relevance = relevance.reshape(njobs, nqueries)\n",
    "        \n",
    "    return relevance, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8cad5e6-de79-4946-9a90-6c29866b2df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_data(sparse = False, uniform = True):\n",
    "    \"\"\"\n",
    "    Generates data for either a sparse or dense simulations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generates dense simulation\n",
    "    if not sparse:\n",
    "        jobs = generate_jobs(njobs = 105)\n",
    "        queries = generate_queries(nqueries = 50)\n",
    "        relevance = generate_relevance(njobs = 105, nqueries = 50)\n",
    "        \n",
    "        return jobs, queries, relevance\n",
    "\n",
    "    # Generates sparse simulations\n",
    "    jobs = generate_jobs(njobs = 200)\n",
    "    queries = generate_queries(nqueries = 1000)\n",
    "        \n",
    "    if not uniform:\n",
    "        relevance, features = generate_relevance(uniform = False, nfeats = 20, njobs = 200, nqueries = 1000)\n",
    "        return jobs, queries, relevance, features\n",
    "    \n",
    "    relevance = generate_relevance(njobs = 200, nqueries = 1000)\n",
    "\n",
    "    return jobs, queries, relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fbc38a4-2fae-4e66-b3c2-bba2f44af8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_data(data, features = False):\n",
    "    \"\"\"\n",
    "    Format the simulated data so that it has multiple rows per session\n",
    "    Example row: (query, job, click, job rank, true relevance)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assign ranks\n",
    "    data = data.assign(\n",
    "        rank = data['query_id'].apply(lambda qid : list(range(10)))\n",
    "    )\n",
    "    \n",
    "    if features:\n",
    "        data = data.explode(['job_ids', 'click', 'rank', 'true_rel', 'features'])\n",
    "    else:\n",
    "        data = data.explode(['job_ids', 'click', 'rank', 'true_rel']) \n",
    "\n",
    "    # Assign query_doc ids\n",
    "    data = data.assign(\n",
    "        qd_id = data[\n",
    "            ['query_id', 'job_ids']\n",
    "        ].apply(\n",
    "            lambda r : r['query_id'] + \"_\" + r['job_ids'],\n",
    "            axis = 1\n",
    "        ).astype(\"category\")\n",
    "    )\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2951b952-7619-4528-8bae-3c51c6944be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_search_results(sparse = False, uniform = True, corr = True):\n",
    "    \"\"\"\n",
    "    Simulate search sessions for a dense or sparse simulation\n",
    "    Additionally has options for introducing correlation between rank and relevance\n",
    "    Can simulate search sessions based on non-uniform or uniformly distributed relevance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate jobs, queries and relevance for the corresponding scenario\n",
    "    if not sparse and uniform:\n",
    "        jobs, queries, relevance = generate_data()\n",
    "    elif sparse and uniform:\n",
    "        jobs, queries, relevance = generate_data(sparse = True)\n",
    "    elif sparse and not uniform:\n",
    "        jobs, queries, relevance, features = generate_data(sparse = True, uniform = False)\n",
    "        \n",
    "    nqueries = len(queries)\n",
    "    njobs = len(jobs)\n",
    "    data = []\n",
    "    count = 1\n",
    "\n",
    "    # Generate fake search data\n",
    "    for qidx in range(nqueries):\n",
    "        \n",
    "        # Only have a small amount of observations per query for sparse simulation\n",
    "        if sparse is True:\n",
    "            if count != 100:\n",
    "                nobs = int(np.random.uniform(1, 4))\n",
    "                count += 1\n",
    "            # Make sure some queries are more popular\n",
    "            nobs = int(np.random.uniform(9, 500))\n",
    "            count = 1\n",
    "        else:\n",
    "            # Dense simulation has a larger amount of observations per query\n",
    "            nobs = int(np.random.uniform(2000, 10000))\n",
    "\n",
    "        for oidx in range(nobs):\n",
    "            # Random user preferences, i.e. noise\n",
    "            user_prefs = np.random.uniform(0.7, 1.0, (njobs,))\n",
    "\n",
    "            # Combine with relevance for user specific sorting\n",
    "            qd_relevance = np.multiply(relevance[:, qidx], user_prefs)\n",
    "            sort_idx = np.argsort(-qd_relevance)\n",
    "            \n",
    "            # If there is no rank-relevance correlation;\n",
    "            # Randomly select 10 from the top 50 that were shown\n",
    "            if corr is False:\n",
    "                search_results = sort_idx[0:50]\n",
    "                np.random.shuffle(search_results)\n",
    "                search_results = search_results[0:10]\n",
    "            else:\n",
    "                # If there is rank-relevance correlation;\n",
    "                # Select results based on higher relevance with equal step size\n",
    "                step_size = int(np.round((njobs / 10) - 1))\n",
    "                search_results = sort_idx[0:step_size*10:step_size]\n",
    "\n",
    "            # Calculate probability of click including position bias\n",
    "            search_results_relevance = qd_relevance[search_results]\n",
    "            click_prob = np.multiply(search_results_relevance, true_bias)\n",
    "\n",
    "            # Simulate clicks\n",
    "            clicks = (np.random.uniform(0, 1, (10,)) < click_prob) * 1\n",
    "        \n",
    "            if uniform is False:\n",
    "                data.append((queries[qidx], jobs[search_results], clicks, relevance[search_results, qidx], features[search_results, qidx]))\n",
    "            else:\n",
    "                data.append((queries[qidx], jobs[search_results], clicks, relevance[search_results, qidx]))\n",
    "    \n",
    "    # Format data\n",
    "    if not uniform:\n",
    "        data = pd.DataFrame(data, columns = ['query_id', 'job_ids', 'click', 'true_rel', 'features'])\n",
    "        return format_data(data, features = True)\n",
    "    \n",
    "    data = pd.DataFrame(data, columns = ['query_id', 'job_ids', 'click', 'true_rel'])\n",
    "    return format_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a97a196d-2322-4608-8d3e-fea6d6d8c796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_qd_counts(data):\n",
    "    \"\"\"\n",
    "    Analyzes the distribution of query-document pairs, to assess sparsity\n",
    "    \"\"\"\n",
    "    \n",
    "    qd_ids = data['qd_id'].cat.codes.astype(int).to_numpy()\n",
    "    qd_cnt = np.bincount(qd_ids)\n",
    "    \n",
    "    percentage_one_observation = (qd_cnt == 1).sum() / len(qd_cnt) * 100\n",
    "    percentage_between_2_and_10 = ((qd_cnt >= 2) & (qd_cnt <= 10)).sum() / len(qd_cnt) * 100\n",
    "    percentage_above_10 = (qd_cnt > 10).sum() / len(qd_cnt) * 100\n",
    "\n",
    "    table = [\n",
    "        [\"Amount of query-document pairs that occurred only once\", percentage_one_observation], \n",
    "        [\"Amount of query-document pairs that occurred 2-10 times:\", percentage_between_2_and_10], \n",
    "        [\"Amount of query-document pairs that occurred more than 10 times\", percentage_above_10],\n",
    "        [\"Highest occurence count: \", qd_cnt.max()],\n",
    "        [\"Amount of rows:\", len(data)],\n",
    "        [\"Amount of query-document pairs: \", len(np.unique(qd_ids))]\n",
    "    ]\n",
    "\n",
    "    return tabulate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "174524eb-bc90-4495-acf9-5d9ae8b64ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Densely simulated data, with and without rank-relevance correlation\n",
    "dense_data_corr = simulate_search_results()\n",
    "dense_data_random = simulate_search_results(corr = False)\n",
    "\n",
    "# Sparsely simulated data, with uniform and non-uniform rank-relevance correlation\n",
    "sparse_data_uniform = simulate_search_results(sparse = True)\n",
    "sparse_data_peaked = simulate_search_results(sparse = True, uniform = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae96c409-65f2-4cc0-ab99-c4780c2f37e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Data, Rank-Relevance correlation:  ---------------------------------------------------------------  --------------\n",
      "Amount of query-document pairs that occurred only once              0.0849979\n",
      "Amount of query-document pairs that occurred 2-10 times:            0.488738\n",
      "Amount of query-document pairs that occurred more than 10 times    99.4263\n",
      "Highest occurence count:                                         5369\n",
      "Amount of rows:                                                     3.08152e+06\n",
      "Amount of query-document pairs:                                  4706\n",
      "---------------------------------------------------------------  --------------\n",
      "Dense Data, No Rank-Relevance correlation:  ---------------------------------------------------------------  --------------\n",
      "Amount of query-document pairs that occurred only once              1.00032\n",
      "Amount of query-document pairs that occurred 2-10 times:            1.80703\n",
      "Amount of query-document pairs that occurred more than 10 times    97.1926\n",
      "Highest occurence count:                                         2092\n",
      "Amount of rows:                                                     3.14349e+06\n",
      "Amount of query-document pairs:                                  3099\n",
      "---------------------------------------------------------------  --------------\n",
      "Sparse Data, Uniform Relevance:  ---------------------------------------------------------------  -----------\n",
      "Amount of query-document pairs that occurred only once              87.2982\n",
      "Amount of query-document pairs that occurred 2-10 times:             6.94882\n",
      "Amount of query-document pairs that occurred more than 10 times      5.75295\n",
      "Highest occurence count:                                            91\n",
      "Amount of rows:                                                  48360\n",
      "Amount of query-document pairs:                                  20320\n",
      "---------------------------------------------------------------  -----------\n",
      "Sparse Data, Non-Uniform Relevance:  ---------------------------------------------------------------  -----------\n",
      "Amount of query-document pairs that occurred only once              87.67\n",
      "Amount of query-document pairs that occurred 2-10 times:             9.01847\n",
      "Amount of query-document pairs that occurred more than 10 times      3.31154\n",
      "Highest occurence count:                                           214\n",
      "Amount of rows:                                                  38610\n",
      "Amount of query-document pairs:                                  20957\n",
      "---------------------------------------------------------------  -----------\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense Data, Rank-Relevance correlation: \", analyze_qd_counts(dense_data_corr))\n",
    "print(\"Dense Data, No Rank-Relevance correlation: \", analyze_qd_counts(dense_data_random))\n",
    "print(\"Sparse Data, Uniform Relevance: \", analyze_qd_counts(sparse_data_uniform))\n",
    "print(\"Sparse Data, Non-Uniform Relevance: \", analyze_qd_counts(sparse_data_peaked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a30311e-12d8-4190-8742-397b34559622",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:simulate_search_results is <function simulate_search_results at 0x7f080acf0ca0>\n",
      "Proper storage of interactively declared classes (or instances\n",
      "of those classes) is not possible! Only instances\n",
      "of classes in real modules on file system can be %store'd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%store simulate_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a2551-63a7-42c8-aeb1-98bbe5220efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
